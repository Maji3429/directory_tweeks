""" ruri-v3-310mãŒä½¿ãˆã‚‹ã‹ã©ã†ã‹ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ """
import time

import torch
import torch.nn.functional as F
from sentence_transformers import SentenceTransformer

start_time = time.time()

# Download from the ğŸ¤— Hub
device = "cuda" if torch.cuda.is_available() else "cpu"
model = SentenceTransformer("./models/ruri-v3-310m", device=device)

# Ruri v3 employs a 1+3 prefix scheme to distinguish between different types of text inputs:
# "" (empty string) is used for encoding semantic meaning.
# "ãƒˆãƒ”ãƒƒã‚¯: " is used for classification, clustering, and encoding topical information.
# "æ¤œç´¢ã‚¯ã‚¨ãƒª: " is used for queries in retrieval tasks.
# "æ¤œç´¢æ–‡æ›¸: " is used for documents to be retrieved.
sentences = [
    "å·ã¹ã‚Šã§ã‚µãƒ¼ãƒ•ãƒœãƒ¼ãƒ‰ã‚’æŒã£ãŸäººãŸã¡ãŒã„ã¾ã™",
    "ã‚µãƒ¼ãƒ•ã‚¡ãƒ¼ãŸã¡ãŒå·ã¹ã‚Šã«ç«‹ã£ã¦ã„ã¾ã™",
    "ãƒˆãƒ”ãƒƒã‚¯: ç‘ ç’ƒè‰²ã®ã‚µãƒ¼ãƒ•ã‚¡ãƒ¼",
    "æ¤œç´¢ã‚¯ã‚¨ãƒª: ç‘ ç’ƒè‰²ã¯ã©ã‚“ãªè‰²ï¼Ÿ",
    "æ¤œç´¢æ–‡æ›¸: ç‘ ç’ƒè‰²ï¼ˆã‚‹ã‚Šã„ã‚ï¼‰ã¯ã€ç´«ã¿ã‚’å¸¯ã³ãŸæ¿ƒã„é’ã€‚åã¯ã€åŠè²´çŸ³ã®ç‘ ç’ƒï¼ˆãƒ©ãƒ”ã‚¹ãƒ©ã‚ºãƒªã€è‹±: lapis lazuliï¼‰ã«ã‚ˆã‚‹ã€‚JISæ…£ç”¨è‰²åã§ã¯ã€Œã“ã„ç´«ã¿ã®é’ã€ï¼ˆç•¥å· dp-pBï¼‰ã¨å®šç¾©ã—ã¦ã„ã‚‹[1][2]ã€‚",
]

embeddings = model.encode(sentences, convert_to_tensor=True)
print(embeddings.size())
# [5, 768]

similarities = F.cosine_similarity(
    embeddings.unsqueeze(0), embeddings.unsqueeze(1), dim=2
)
print(similarities)
# [[1.0000, 0.9603, 0.8157, 0.7074, 0.6916],
#  [0.9603, 1.0000, 0.8192, 0.7014, 0.6819],
#  [0.8157, 0.8192, 1.0000, 0.8701, 0.8470],
#  [0.7074, 0.7014, 0.8701, 1.0000, 0.9746],
#  [0.6916, 0.6819, 0.8470, 0.9746, 1.0000]]

end_time = time.time()  # å®Ÿè¡Œçµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²
print(f"å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’") # çµŒéæ™‚é–“ã‚’è¡¨ç¤º
